#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Created on Fri Dec 13 16:21:09 2013

@author: Alexander Bikadorov, Marcelo Millani

Dependencies:
- TMalign needs to be in PATH
- paratmalign needs to be in PATH
- blastp needs to be in PATH
- abinitio needs to be in PATH (a link to the compbio_app.* executable)
- grep needs to be in PATH
- head needs to be in PATH
- biopython needs to be in PYTHONPATH

"""

import sys
import logging
import argparse
import os
import subprocess
import itertools

import Bio.PDB

import _myutils

DEVNULL = open(os.devnull, "w")
TMALIGN_SEPARATOR = "# SEPARATOR #"

TMALIGN_EXE = 'TMalign'
PARATMALIGN_EXE = 'paratmalign.sh'
BLASTP_EXE = 'blastp'
ABINITIO_EXE = 'abinitio'

NUM_DECOYS = 100 # number of decoys generated by rosetta
NUM_USED_DECOYS = 5 # number of decoys used for database comparison, TODO
NUM_STRUC_TEMPLATES = 100 # number of templates selected by structure comparison per decoy
NUM_CONSTR_TEMPLATES = 1 # number of templates used for constraint extraction per iteration
WEIGHT_STRUC = 1
WEIGHT_SEQ = 0.014 # TODO
D = 1 # lower bound distance in angstrom for constraint extraction
MIN_RES_SEQ_DIST = 10 # minimum distance between residues in template sequence to be considered "far away"
MAX_RES_STRUC_DIST = 10 # maximum distance of residues in template structure to be considered bound to each other
SD = '0.2' # scaling value for constraint distance, TODO
PROCESSES_ABINITIO = 3 # number of parallel abinitio executions
PROCESSES_TMALIGN = 16 # number of parallel TMAlign executions

def _arguments():
    parser = argparse.ArgumentParser()
    parser.add_argument("target_fasta_file", type=str, help="Target fasta file")
    parser.add_argument("pdb_dir", type=str, help="Path to structure database (directory with pdb files)")
    parser.add_argument("fasta_dir", type=str, help="Path to sequence database (directory with fasta files)")
    parser.add_argument("rosetta_database", type=str, help="Path to the database which will be used by Rosetta's abinitio")
    parser.add_argument("-s", "--skip-rosetta", action='store_true', help="Skip rosetta execution at the beginning (assume models are already generated)")
    parser.add_argument("-s2", "--skip-ros-end", action='store_true', help="Skip rosetta execution with constraints at the end of the process")
    parser.add_argument("-c", "--ros-constr-file", type=str, help="Constraint file for rosetta execution at beginning")
    parser.add_argument("-n", "--num-decoys", type=int, help="Number of decoys generated by rosetta (default: "+str(NUM_DECOYS)+")")
    return parser.parse_args()

def _check_executables(args):
    exe_list = [TMALIGN_EXE, PARATMALIGN_EXE, BLASTP_EXE]
    exe_list += [] if args.skip_rosetta and args.skip_ros_end else [ABINITIO_EXE]
    if not all([_myutils.is_executable(exe_str) for exe_str in exe_list]):
        print('required executable(s) not found (aborting)')
        sys.exit(1)

def _run_rosetta(target_base_dir, rosetta_database, num_decoys, constr_file_path=None):
    """Run the 'abinitio' executable in parallel"""
    cur_dir = os.getcwd()
    os.chdir(target_base_dir)
    _myutils.move('models', 'models', into_folder=False)

    abinitio = [ABINITIO_EXE, "@flags", "-database", rosetta_database, "-out:level", "200"]
    if constr_file_path:
        abinitio += ["-constraints:cst_file", constr_file_path, "-constraints:cst_weight", "1.0"]

    # equally assign decoys to processes
    procs = min(PROCESSES_ABINITIO, num_decoys)
    avg = num_decoys / procs
    num_decoys_list = [round((i+1)*avg) - round(i*avg) for i in range(procs)]

    popens = []
    for i, num_decoys_proc in zip(range(procs), num_decoys_list):
        abinitio_proc = abinitio + ["--nstruct", str(num_decoys_proc-1), "-out:output_tag", str(i)+'_']
        print("Running abinitio:\n%s"%(" ".join(abinitio_proc)))
        popens.append(subprocess.Popen(abinitio_proc))

    for popen in popens:
        ret_code = popen.wait()
        print('Abinitio process terminated with return code '+str(ret_code))

    # merge score files
    merge_lines = []
    for i in range(procs):
        lines_list = _myutils.read_file_lines(os.path.join('models', str(i)+'_score.fsc'))
        merge_lines += lines_list if i == 0 else lines_list[1:]
    _myutils.write_file(os.path.join('models', 'score.fsc'), '\n'.join(merge_lines))

    os.chdir(cur_dir)
    print("done with abinitio")

def _read_scorefile(target_base_dir):
    # load score file input
    score_file_str = os.path.join(target_base_dir, 'models', 'score.fsc')
    lines_list = _myutils.read_file_lines(score_file_str)
    
    # create list of lists with all fields
    field_list = [str_.split() for str_ in lines_list]
    # filter irrelevant lines
    field_list = [l for l in field_list if l[0] == "SCORE:"] 
    # create list of dictionaries (with keys from first line in file)
    field_dict_list = [dict(zip(field_list[0], l)) for l in field_list[1:]]
    
    # sort list
    field_dict_list.sort(key=lambda d: float(d["score"])) # smaller score better
    
    print('decoy scores:')
    print('score gdtmm_full description')
    for d in field_dict_list:
        print(d["score"], d["gdtmm_full"], d["description"])
        
    return field_dict_list

def _run(args, shell=False, stderr=None):
    return subprocess.check_output(args, shell=shell, stderr=stderr).rstrip().decode("utf-8")

def _run_para_tmalign(decoy_pdb, templates_pdbs):
    scoreParser = r"grep ^TM-score | grep [0-9]*\\.[0-9]* -o | head -n 1"
    args = ["%s %d '%s' '%s' %s"%(PARATMALIGN_EXE, PROCESSES_TMALIGN, decoy_pdb, TMALIGN_SEPARATOR , "'"+"' '".join(templates_pdbs) + "'")]
    all_ = _run(args, shell=True, stderr=DEVNULL)
    # As there is an separator after every execution, the last element will be empty
    executions = all_.split(TMALIGN_SEPARATOR)

    scores = []
    # gets the score of each execution
    for i in range(0,len(executions)-1,2):
        e = executions[i]
        name = os.path.basename(executions[i+1]).rstrip()
        try:
            parsit = ["echo \"%s\" | %s"%(e,scoreParser)]            
            score = _run(parsit, shell=True)
            scores.append((name,float(score)))
        except:
            pass
    
    return scores

def _para_tmalign(decoy_pdb_file, pdb_dir):
    print('running paraTMAlign for '+decoy_pdb_file+'...')
    scores = []
    CHUNK_SIZE = 100 * PROCESSES_TMALIGN
    files = _myutils.files_in_dir(pdb_dir, '*.pdb') + _myutils.files_in_dir(pdb_dir, '*.ent')
    # run tmalign for each template in database
    for chunk in _myutils.group_it(files, CHUNK_SIZE):
        scores += _run_para_tmalign(decoy_pdb_file, chunk)
        print("%d/%d" % (len(scores), len(files)))
    
    scores.sort(key=lambda t: t[1], reverse=True) # higher score better
    print("Scores.len = %d"%(len(scores)))
    return scores

#BLAST_OUTP = '10 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore qseq sseq'
BLAST_OUTP = ["10 bitscore score"]
def _run_blast(target_fasta_file, template_fasta_file):
    args = [BLASTP_EXE, '-query', target_fasta_file, '-subject', template_fasta_file, '-outfmt'] + BLAST_OUTP
    out = _run(args)
    return float(out.split(',')[0]) if len(out) else 0

def _residue_indices(res_list, bound_list):
    """Get a list of absolute residue numbers for a TMalign mapping"""
    it = itertools.count(1)
    return [a for a, x in zip((next(it) if a != '-' else None for a in res_list), bound_list) if x == ':']
    
def _run_tmalign_constr(decoy_pdb_file, template_pdb_file, d):
    """Run TMalign to get a sequence alignment mapping (based on structure) between decoy and template residues.
       Return a dictionary with template residue numbers as keys and mapped target residue numbers as values.
       d: minimum distance in angstrom.
    """
    args = [TMALIGN_EXE+" "+decoy_pdb_file+" "+template_pdb_file+" -d "+str(d)+" | tail -n 4"]
    outp_lines = _run(args, shell=True).splitlines()
    target_res_list = _residue_indices(outp_lines[0], outp_lines[1])
    template_res_list = _residue_indices(outp_lines[2], outp_lines[1])
    return dict(zip(template_res_list, target_res_list))

def _get_atom_distance(struc_res_list, res_num1, res_num2):
    """Calculate distance of two residues in structure"""
    atom1 = struc_res_list[res_num1-1]["CA"]
    atom2 = struc_res_list[res_num2-1]["CA"]
    return atom1 - atom2

def _get_constraints(template_pdb_file, res_dict):
    """Get target distance constraints between residue pairs (their CA atoms respectively).
    """
    template_res_list = sorted(res_dict.keys())
    parser = Bio.PDB.PDBParser(PERMISSIVE=1, QUIET=True) # warnings are ignored
    structure = parser.get_structure('id', template_pdb_file)
    struc_res_list = list(structure.get_residues())
    res_combs = ((n1, n2) for n1, n2 in itertools.combinations(template_res_list, 2) if abs(n1 - n2) >= MIN_RES_SEQ_DIST)
    template_dist_list = [(r1, r2, _get_atom_distance(struc_res_list, r1, r2)) for r1, r2 in res_combs] 
    print('template residue distances : ', template_dist_list)
    return [(res_dict[r1], res_dict[r2]) for r1, r2, d in template_dist_list if d >= MAX_RES_STRUC_DIST]

def main(argv=sys.argv):
    logging.getLogger().setLevel(logging.INFO)
    
    args = _arguments()
    _check_executables(args)
    
    target_fasta_path = os.path.abspath(args.target_fasta_file)
    target_base_dir = os.path.join(*_myutils.split_path(target_fasta_path)[:-2])
    pdb_dir = os.path.abspath(args.pdb_dir)
    fasta_dir = os.path.abspath(args.fasta_dir)
    rosetta_database = os.path.abspath(args.rosetta_database)
    rosetta_constr_file = os.path.abspath(args.ros_constr_file) if args.ros_constr_file else None
    num_decoys = args.num_decoys if args.num_decoys else NUM_DECOYS
        
    # step 1: run compbio_app
    if not args.skip_rosetta:
        _run_rosetta(target_base_dir, rosetta_database, num_decoys, constr_file_path=rosetta_constr_file)
    
    # step 2: read scorefile 
    field_dict_list = _read_scorefile(target_base_dir)

    # step 3: find template scores for decoys  
    scores = []
    for decoy_dict in field_dict_list[:NUM_USED_DECOYS]:
        print('processed decoy: '+decoy_dict['description'])
        
        # step 3.1: get structure scores with tmalign
        decoy_pdb_file = os.path.join(target_base_dir, 'models', decoy_dict['description'] + '.pdb')
        struc_scores = _para_tmalign(decoy_pdb_file, pdb_dir)
    
        struc_scores = struc_scores[:NUM_STRUC_TEMPLATES]
        
        # step 3.2: get sequence scores
        for template_pdb_file, struc_score in struc_scores:
            template_fasta_file = os.path.join(fasta_dir, template_pdb_file.rstrip('.pdb') + '.fasta')
            seq_score = _run_blast(target_fasta_path, template_fasta_file)
            scores.append((decoy_dict['description'], template_pdb_file, struc_score, seq_score, WEIGHT_STRUC * struc_score + WEIGHT_SEQ * seq_score))
    
    scores.sort(key=lambda t: t[4], reverse=True)
        
    print('decoy - template scores :')
    print('\n'.join(str(t) for t in scores))
    score_file_str = os.path.join(target_base_dir, "my_scores.txt")
    _myutils.write_file(score_file_str , '\n'.join(str(t) for t in scores))

    # step 5: get constraints from selected templates
    constr_template = scores[:NUM_CONSTR_TEMPLATES]
    res_pairs = []
    for decoy_id, template_file, _, _, _ in constr_template:
        decoy_pdb_path = os.path.join(target_base_dir, 'models', decoy_id + '.pdb')
        template_pdb_path = os.path.join(pdb_dir, template_file)
        # get residue alignment mapping
        res_dict = _run_tmalign_constr(decoy_pdb_path, template_pdb_path, D)
        # get final residue pairs for target structure
        res_pairs += _get_constraints(template_pdb_path, res_dict)
    
    # remove inconsistent pairs
    res_pairs = _myutils.remove_dups(res_pairs, comp_item_index=0)
    res_pairs = _myutils.remove_dups(res_pairs, comp_item_index=1)
    
    # save constraint file
    # AtomPair: Atom1_Name Atom1_ResNum Atom2_Name Atom2_ResNum Func_Type Func_Def
    # AtomPair SG 5 V1 32 HARMONIC 0.0 0.2
    ros_constr = ['AtomPair CA '+str(n1)+' CA '+str(n2)+' HARMONIC 0.0 '+SD for n1, n2 in res_pairs]
    print('\n'.join(ros_constr))
    constr_file_path = os.path.join(target_base_dir,'inputs', 'ros_constraints.txt')
    constr_file_path = _myutils.write_file(constr_file_path, '\n'.join(ros_constr) + '\n')
    
    # step 6: runs abinitio with the constraints
    if not args.skip_ros_end:
        _run_rosetta(target_base_dir, rosetta_database, num_decoys, constr_file_path=constr_file_path)
    
    DEVNULL.close()
    print("DONE!")

if __name__ == "__main__":
    sys.exit(main())
